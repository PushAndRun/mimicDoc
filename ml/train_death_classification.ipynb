{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_death_classification.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP/xbzbvd2On90DphIO+ta0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"J7zC4c7b6J4N"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","import os\n","from os import path\n","import tempfile\n","import time\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import pandas as pd\n","pd.options.mode.chained_assignment = None\n","\n","import seaborn as sns\n","\n","import sklearn\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4a3Dv_B6QMY","executionInfo":{"status":"ok","timestamp":1622473512355,"user_tz":-120,"elapsed":19073,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"a18f2935-30c3-412e-acfa-a30aaa38c66e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NQkDxBd56SHA"},"source":["mpl.rcParams['figure.figsize'] = (12, 10)\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xZIvr8w60yO"},"source":["### DataFrame name:"]},{"cell_type":"code","metadata":{"id":"2uZlSH5m64So"},"source":["df_name = \"95\"\n","layer1nodes = 128\n","suffix = \"\"\n","\n","df_path = f\"/content/drive/MyDrive/uni/RoboDoc/ml/{df_name}\"\n","\n","model_name = f\"df{df_name}_n{layer1nodes}{suffix}\"\n","\n","model_path = f\"{df_path}/{model_name}\"\n","\n","if path.exists(model_path) == False:\n","  os.mkdir(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyYeWl-H6WKH"},"source":["df = pd.read_pickle(f\"{df_path}/dataframe_{df_name}.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"Pds9G-D06ulg","executionInfo":{"status":"ok","timestamp":1622473546782,"user_tz":-120,"elapsed":17,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"ca022d9a-920f-45a8-c5f3-ca9eede138d8"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>weight</th>\n","      <th>meanbp_mean</th>\n","      <th>meanbp_min</th>\n","      <th>meanbp_max</th>\n","      <th>resprate_min</th>\n","      <th>resprate_max</th>\n","      <th>resprate_mean</th>\n","      <th>tempc_mean</th>\n","      <th>glucose_min</th>\n","      <th>glucose_max</th>\n","      <th>glucose_mean</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>...</th>\n","      <th>1399</th>\n","      <th>1400</th>\n","      <th>1401</th>\n","      <th>1402</th>\n","      <th>1403</th>\n","      <th>1404</th>\n","      <th>1405</th>\n","      <th>1406</th>\n","      <th>1407</th>\n","      <th>1408</th>\n","      <th>1409</th>\n","      <th>1410</th>\n","      <th>1411</th>\n","      <th>1412</th>\n","      <th>1413</th>\n","      <th>1414</th>\n","      <th>1415</th>\n","      <th>1416</th>\n","      <th>1417</th>\n","      <th>1418</th>\n","      <th>1419</th>\n","      <th>1420</th>\n","      <th>1421</th>\n","      <th>1422</th>\n","      <th>1423</th>\n","      <th>1424</th>\n","      <th>1425</th>\n","      <th>1426</th>\n","      <th>1427</th>\n","      <th>1428</th>\n","      <th>1429</th>\n","      <th>1430</th>\n","      <th>1431</th>\n","      <th>1432</th>\n","      <th>1433</th>\n","      <th>1434</th>\n","      <th>1435</th>\n","      <th>length_of_stay_hospital</th>\n","      <th>died_in_hospital</th>\n","      <th>days_to_death</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.578947</td>\n","      <td>1.0</td>\n","      <td>0.317726</td>\n","      <td>0.510949</td>\n","      <td>0.448</td>\n","      <td>0.463768</td>\n","      <td>0.182243</td>\n","      <td>0.311475</td>\n","      <td>0.205128</td>\n","      <td>0.471545</td>\n","      <td>0.132229</td>\n","      <td>0.081716</td>\n","      <td>0.070480</td>\n","      <td>0.364043</td>\n","      <td>0.456363</td>\n","      <td>0.553465</td>\n","      <td>0.421632</td>\n","      <td>0.460921</td>\n","      <td>0.230861</td>\n","      <td>0.364046</td>\n","      <td>0.150707</td>\n","      <td>0.616188</td>\n","      <td>0.387668</td>\n","      <td>0.408317</td>\n","      <td>0.490798</td>\n","      <td>0.149982</td>\n","      <td>0.348723</td>\n","      <td>0.410745</td>\n","      <td>0.410293</td>\n","      <td>0.375371</td>\n","      <td>0.294447</td>\n","      <td>0.420647</td>\n","      <td>0.483331</td>\n","      <td>0.459979</td>\n","      <td>0.507799</td>\n","      <td>0.475832</td>\n","      <td>0.325318</td>\n","      <td>0.623990</td>\n","      <td>0.463194</td>\n","      <td>0.489838</td>\n","      <td>...</td>\n","      <td>0.451496</td>\n","      <td>0.469973</td>\n","      <td>0.400281</td>\n","      <td>0.444384</td>\n","      <td>0.462615</td>\n","      <td>0.452883</td>\n","      <td>0.471940</td>\n","      <td>0.483980</td>\n","      <td>0.506908</td>\n","      <td>0.452392</td>\n","      <td>0.423360</td>\n","      <td>0.487804</td>\n","      <td>0.445244</td>\n","      <td>0.450775</td>\n","      <td>0.454335</td>\n","      <td>0.481367</td>\n","      <td>0.511838</td>\n","      <td>0.448053</td>\n","      <td>0.476317</td>\n","      <td>0.403012</td>\n","      <td>0.478884</td>\n","      <td>0.382877</td>\n","      <td>0.484026</td>\n","      <td>0.464456</td>\n","      <td>0.431639</td>\n","      <td>0.490876</td>\n","      <td>0.452463</td>\n","      <td>0.459690</td>\n","      <td>0.392050</td>\n","      <td>0.466125</td>\n","      <td>0.426711</td>\n","      <td>0.454286</td>\n","      <td>0.472632</td>\n","      <td>0.478366</td>\n","      <td>0.446211</td>\n","      <td>0.394671</td>\n","      <td>0.496392</td>\n","      <td>10.61</td>\n","      <td>0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.526316</td>\n","      <td>1.0</td>\n","      <td>0.266388</td>\n","      <td>0.562044</td>\n","      <td>0.552</td>\n","      <td>0.326087</td>\n","      <td>0.275701</td>\n","      <td>0.311475</td>\n","      <td>0.358974</td>\n","      <td>0.621500</td>\n","      <td>0.238798</td>\n","      <td>0.136874</td>\n","      <td>0.127681</td>\n","      <td>0.273684</td>\n","      <td>0.376123</td>\n","      <td>0.547164</td>\n","      <td>0.110738</td>\n","      <td>0.426807</td>\n","      <td>0.536119</td>\n","      <td>0.491203</td>\n","      <td>0.391604</td>\n","      <td>0.530948</td>\n","      <td>0.233122</td>\n","      <td>0.285013</td>\n","      <td>0.545109</td>\n","      <td>0.354498</td>\n","      <td>0.474979</td>\n","      <td>0.550267</td>\n","      <td>0.334811</td>\n","      <td>0.389495</td>\n","      <td>0.428739</td>\n","      <td>0.409122</td>\n","      <td>0.567919</td>\n","      <td>0.344699</td>\n","      <td>0.625053</td>\n","      <td>0.610797</td>\n","      <td>0.553657</td>\n","      <td>0.749607</td>\n","      <td>0.511606</td>\n","      <td>0.530965</td>\n","      <td>...</td>\n","      <td>0.461610</td>\n","      <td>0.449144</td>\n","      <td>0.512688</td>\n","      <td>0.538255</td>\n","      <td>0.435267</td>\n","      <td>0.407335</td>\n","      <td>0.325974</td>\n","      <td>0.536346</td>\n","      <td>0.589737</td>\n","      <td>0.381024</td>\n","      <td>0.420131</td>\n","      <td>0.466249</td>\n","      <td>0.457916</td>\n","      <td>0.385405</td>\n","      <td>0.433735</td>\n","      <td>0.485510</td>\n","      <td>0.500216</td>\n","      <td>0.520159</td>\n","      <td>0.308390</td>\n","      <td>0.373872</td>\n","      <td>0.574494</td>\n","      <td>0.369746</td>\n","      <td>0.538771</td>\n","      <td>0.360851</td>\n","      <td>0.739281</td>\n","      <td>0.507123</td>\n","      <td>0.537671</td>\n","      <td>0.578029</td>\n","      <td>0.341291</td>\n","      <td>0.479565</td>\n","      <td>0.496294</td>\n","      <td>0.530438</td>\n","      <td>0.448549</td>\n","      <td>0.252540</td>\n","      <td>0.324613</td>\n","      <td>0.363326</td>\n","      <td>0.554716</td>\n","      <td>60.01</td>\n","      <td>0</td>\n","      <td>28.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.750000</td>\n","      <td>1.0</td>\n","      <td>0.301003</td>\n","      <td>0.430657</td>\n","      <td>0.520</td>\n","      <td>0.264493</td>\n","      <td>0.252336</td>\n","      <td>0.311475</td>\n","      <td>0.282051</td>\n","      <td>0.579301</td>\n","      <td>0.172827</td>\n","      <td>0.158325</td>\n","      <td>0.121553</td>\n","      <td>0.395083</td>\n","      <td>0.169589</td>\n","      <td>0.334067</td>\n","      <td>0.220507</td>\n","      <td>0.569524</td>\n","      <td>0.656565</td>\n","      <td>0.469736</td>\n","      <td>0.432011</td>\n","      <td>0.273094</td>\n","      <td>0.391768</td>\n","      <td>0.399913</td>\n","      <td>0.451684</td>\n","      <td>0.371500</td>\n","      <td>0.413204</td>\n","      <td>0.452774</td>\n","      <td>0.506542</td>\n","      <td>0.468486</td>\n","      <td>0.377149</td>\n","      <td>0.424454</td>\n","      <td>0.546171</td>\n","      <td>0.337927</td>\n","      <td>0.519142</td>\n","      <td>0.433113</td>\n","      <td>0.459250</td>\n","      <td>0.547283</td>\n","      <td>0.418791</td>\n","      <td>0.246391</td>\n","      <td>...</td>\n","      <td>0.449899</td>\n","      <td>0.485622</td>\n","      <td>0.389515</td>\n","      <td>0.429574</td>\n","      <td>0.429249</td>\n","      <td>0.471155</td>\n","      <td>0.437163</td>\n","      <td>0.490338</td>\n","      <td>0.481424</td>\n","      <td>0.457246</td>\n","      <td>0.418201</td>\n","      <td>0.462029</td>\n","      <td>0.441233</td>\n","      <td>0.449240</td>\n","      <td>0.491772</td>\n","      <td>0.454483</td>\n","      <td>0.463925</td>\n","      <td>0.461486</td>\n","      <td>0.504925</td>\n","      <td>0.400865</td>\n","      <td>0.494406</td>\n","      <td>0.378507</td>\n","      <td>0.477134</td>\n","      <td>0.432877</td>\n","      <td>0.472330</td>\n","      <td>0.488397</td>\n","      <td>0.439208</td>\n","      <td>0.479703</td>\n","      <td>0.392930</td>\n","      <td>0.463207</td>\n","      <td>0.435096</td>\n","      <td>0.468214</td>\n","      <td>0.502176</td>\n","      <td>0.458563</td>\n","      <td>0.427514</td>\n","      <td>0.433890</td>\n","      <td>0.472819</td>\n","      <td>6.33</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.723684</td>\n","      <td>1.0</td>\n","      <td>0.287625</td>\n","      <td>0.459854</td>\n","      <td>0.448</td>\n","      <td>0.311594</td>\n","      <td>0.135514</td>\n","      <td>0.327869</td>\n","      <td>0.282051</td>\n","      <td>0.661340</td>\n","      <td>0.177901</td>\n","      <td>0.136874</td>\n","      <td>0.111338</td>\n","      <td>0.526008</td>\n","      <td>0.478596</td>\n","      <td>0.180866</td>\n","      <td>0.254238</td>\n","      <td>0.537086</td>\n","      <td>0.531832</td>\n","      <td>0.402759</td>\n","      <td>0.404065</td>\n","      <td>0.667459</td>\n","      <td>0.410731</td>\n","      <td>0.404282</td>\n","      <td>0.536918</td>\n","      <td>0.121502</td>\n","      <td>0.333665</td>\n","      <td>0.521657</td>\n","      <td>0.404536</td>\n","      <td>0.423838</td>\n","      <td>0.230396</td>\n","      <td>0.438998</td>\n","      <td>0.398284</td>\n","      <td>0.421840</td>\n","      <td>0.543324</td>\n","      <td>0.451551</td>\n","      <td>0.291949</td>\n","      <td>0.525944</td>\n","      <td>0.445496</td>\n","      <td>0.616157</td>\n","      <td>...</td>\n","      <td>0.596357</td>\n","      <td>0.217947</td>\n","      <td>0.280199</td>\n","      <td>0.272401</td>\n","      <td>0.668163</td>\n","      <td>0.296712</td>\n","      <td>0.558334</td>\n","      <td>0.420042</td>\n","      <td>0.856998</td>\n","      <td>0.212607</td>\n","      <td>0.282565</td>\n","      <td>0.785182</td>\n","      <td>0.540643</td>\n","      <td>0.365364</td>\n","      <td>0.432607</td>\n","      <td>0.569005</td>\n","      <td>0.495348</td>\n","      <td>0.799436</td>\n","      <td>0.449475</td>\n","      <td>0.424703</td>\n","      <td>0.472156</td>\n","      <td>0.122250</td>\n","      <td>0.406786</td>\n","      <td>0.473348</td>\n","      <td>0.339143</td>\n","      <td>0.527691</td>\n","      <td>0.533946</td>\n","      <td>0.266586</td>\n","      <td>0.357349</td>\n","      <td>0.398143</td>\n","      <td>0.370468</td>\n","      <td>0.660747</td>\n","      <td>0.717472</td>\n","      <td>0.474361</td>\n","      <td>0.420944</td>\n","      <td>0.505622</td>\n","      <td>0.386065</td>\n","      <td>6.02</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.394737</td>\n","      <td>0.0</td>\n","      <td>0.266388</td>\n","      <td>0.394161</td>\n","      <td>0.400</td>\n","      <td>0.221014</td>\n","      <td>0.369159</td>\n","      <td>0.262295</td>\n","      <td>0.307692</td>\n","      <td>0.558266</td>\n","      <td>0.220190</td>\n","      <td>0.165475</td>\n","      <td>0.131767</td>\n","      <td>0.042262</td>\n","      <td>0.416218</td>\n","      <td>0.284472</td>\n","      <td>0.368381</td>\n","      <td>0.484330</td>\n","      <td>0.438105</td>\n","      <td>0.469459</td>\n","      <td>0.463685</td>\n","      <td>0.314813</td>\n","      <td>0.417263</td>\n","      <td>0.441096</td>\n","      <td>0.432818</td>\n","      <td>0.408774</td>\n","      <td>0.364042</td>\n","      <td>0.458567</td>\n","      <td>0.413726</td>\n","      <td>0.471160</td>\n","      <td>0.389235</td>\n","      <td>0.456072</td>\n","      <td>0.467205</td>\n","      <td>0.485622</td>\n","      <td>0.483965</td>\n","      <td>0.394747</td>\n","      <td>0.438353</td>\n","      <td>0.481559</td>\n","      <td>0.474867</td>\n","      <td>0.499240</td>\n","      <td>...</td>\n","      <td>0.448158</td>\n","      <td>0.495605</td>\n","      <td>0.405968</td>\n","      <td>0.455817</td>\n","      <td>0.454258</td>\n","      <td>0.474887</td>\n","      <td>0.451451</td>\n","      <td>0.502501</td>\n","      <td>0.488990</td>\n","      <td>0.505782</td>\n","      <td>0.402557</td>\n","      <td>0.451956</td>\n","      <td>0.446834</td>\n","      <td>0.456246</td>\n","      <td>0.468295</td>\n","      <td>0.462567</td>\n","      <td>0.472640</td>\n","      <td>0.474050</td>\n","      <td>0.516415</td>\n","      <td>0.400370</td>\n","      <td>0.477945</td>\n","      <td>0.391255</td>\n","      <td>0.456062</td>\n","      <td>0.430766</td>\n","      <td>0.487166</td>\n","      <td>0.483881</td>\n","      <td>0.461030</td>\n","      <td>0.494312</td>\n","      <td>0.403677</td>\n","      <td>0.473061</td>\n","      <td>0.455825</td>\n","      <td>0.497913</td>\n","      <td>0.516634</td>\n","      <td>0.459559</td>\n","      <td>0.400484</td>\n","      <td>0.416300</td>\n","      <td>0.465035</td>\n","      <td>2.01</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1452 columns</p>\n","</div>"],"text/plain":["        age  gender  ...  died_in_hospital  days_to_death\n","0  0.578947     1.0  ...                 0            5.0\n","1  0.526316     1.0  ...                 0           28.0\n","2  0.750000     1.0  ...                 0            NaN\n","3  0.723684     1.0  ...                 0            NaN\n","4  0.394737     0.0  ...                 0            NaN\n","\n","[5 rows x 1452 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"aASUqNae7DQp","executionInfo":{"status":"ok","timestamp":1622473558894,"user_tz":-120,"elapsed":12122,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"75bba5d7-be0b-4ec3-b576-60fe43f5ca43"},"source":["df.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>weight</th>\n","      <th>meanbp_mean</th>\n","      <th>meanbp_min</th>\n","      <th>meanbp_max</th>\n","      <th>resprate_min</th>\n","      <th>resprate_max</th>\n","      <th>resprate_mean</th>\n","      <th>tempc_mean</th>\n","      <th>glucose_min</th>\n","      <th>glucose_max</th>\n","      <th>glucose_mean</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>...</th>\n","      <th>1398</th>\n","      <th>1399</th>\n","      <th>1400</th>\n","      <th>1401</th>\n","      <th>1402</th>\n","      <th>1403</th>\n","      <th>1404</th>\n","      <th>1405</th>\n","      <th>1406</th>\n","      <th>1407</th>\n","      <th>1408</th>\n","      <th>1409</th>\n","      <th>1410</th>\n","      <th>1411</th>\n","      <th>1412</th>\n","      <th>1413</th>\n","      <th>1414</th>\n","      <th>1415</th>\n","      <th>1416</th>\n","      <th>1417</th>\n","      <th>1418</th>\n","      <th>1419</th>\n","      <th>1420</th>\n","      <th>1421</th>\n","      <th>1422</th>\n","      <th>1423</th>\n","      <th>1424</th>\n","      <th>1425</th>\n","      <th>1426</th>\n","      <th>1427</th>\n","      <th>1428</th>\n","      <th>1429</th>\n","      <th>1430</th>\n","      <th>1431</th>\n","      <th>1432</th>\n","      <th>1433</th>\n","      <th>1434</th>\n","      <th>1435</th>\n","      <th>length_of_stay_hospital</th>\n","      <th>days_to_death</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>...</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>48866.000000</td>\n","      <td>21444.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.650590</td>\n","      <td>0.562129</td>\n","      <td>0.266388</td>\n","      <td>0.445591</td>\n","      <td>0.467871</td>\n","      <td>0.296353</td>\n","      <td>0.283202</td>\n","      <td>0.313857</td>\n","      <td>0.301810</td>\n","      <td>0.608499</td>\n","      <td>0.180799</td>\n","      <td>0.162328</td>\n","      <td>0.120644</td>\n","      <td>0.262751</td>\n","      <td>0.404717</td>\n","      <td>0.369815</td>\n","      <td>0.386130</td>\n","      <td>0.490819</td>\n","      <td>0.443567</td>\n","      <td>0.466785</td>\n","      <td>0.455792</td>\n","      <td>0.338298</td>\n","      <td>0.435870</td>\n","      <td>0.436951</td>\n","      <td>0.453190</td>\n","      <td>0.424337</td>\n","      <td>0.405111</td>\n","      <td>0.463086</td>\n","      <td>0.427688</td>\n","      <td>0.462124</td>\n","      <td>0.394588</td>\n","      <td>0.462222</td>\n","      <td>0.465889</td>\n","      <td>0.468876</td>\n","      <td>0.499696</td>\n","      <td>0.397292</td>\n","      <td>0.443534</td>\n","      <td>0.482537</td>\n","      <td>0.492243</td>\n","      <td>0.495614</td>\n","      <td>...</td>\n","      <td>0.493126</td>\n","      <td>0.455065</td>\n","      <td>0.485833</td>\n","      <td>0.393557</td>\n","      <td>0.442577</td>\n","      <td>0.434469</td>\n","      <td>0.455794</td>\n","      <td>0.446471</td>\n","      <td>0.488138</td>\n","      <td>0.476483</td>\n","      <td>0.459526</td>\n","      <td>0.418764</td>\n","      <td>0.458832</td>\n","      <td>0.430521</td>\n","      <td>0.447943</td>\n","      <td>0.475411</td>\n","      <td>0.464631</td>\n","      <td>0.472509</td>\n","      <td>0.451623</td>\n","      <td>0.493592</td>\n","      <td>0.408311</td>\n","      <td>0.494183</td>\n","      <td>0.380829</td>\n","      <td>0.483436</td>\n","      <td>0.434358</td>\n","      <td>0.469886</td>\n","      <td>0.486177</td>\n","      <td>0.448833</td>\n","      <td>0.485848</td>\n","      <td>0.402913</td>\n","      <td>0.468509</td>\n","      <td>0.443845</td>\n","      <td>0.470479</td>\n","      <td>0.494462</td>\n","      <td>0.457499</td>\n","      <td>0.425124</td>\n","      <td>0.426741</td>\n","      <td>0.480849</td>\n","      <td>9.990334</td>\n","      <td>12.628474</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.228188</td>\n","      <td>0.496130</td>\n","      <td>0.072670</td>\n","      <td>0.082701</td>\n","      <td>0.109438</td>\n","      <td>0.094120</td>\n","      <td>0.086976</td>\n","      <td>0.106607</td>\n","      <td>0.102414</td>\n","      <td>0.060794</td>\n","      <td>0.058942</td>\n","      <td>0.087584</td>\n","      <td>0.045213</td>\n","      <td>0.177362</td>\n","      <td>0.173491</td>\n","      <td>0.128753</td>\n","      <td>0.133040</td>\n","      <td>0.122872</td>\n","      <td>0.116459</td>\n","      <td>0.130797</td>\n","      <td>0.117562</td>\n","      <td>0.119592</td>\n","      <td>0.122049</td>\n","      <td>0.100812</td>\n","      <td>0.108233</td>\n","      <td>0.109583</td>\n","      <td>0.093970</td>\n","      <td>0.099768</td>\n","      <td>0.124292</td>\n","      <td>0.123155</td>\n","      <td>0.125566</td>\n","      <td>0.104172</td>\n","      <td>0.093376</td>\n","      <td>0.095048</td>\n","      <td>0.094871</td>\n","      <td>0.091836</td>\n","      <td>0.093674</td>\n","      <td>0.087280</td>\n","      <td>0.100602</td>\n","      <td>0.078760</td>\n","      <td>...</td>\n","      <td>0.042387</td>\n","      <td>0.041216</td>\n","      <td>0.040174</td>\n","      <td>0.034711</td>\n","      <td>0.044265</td>\n","      <td>0.042217</td>\n","      <td>0.034033</td>\n","      <td>0.037864</td>\n","      <td>0.036830</td>\n","      <td>0.044027</td>\n","      <td>0.046013</td>\n","      <td>0.030993</td>\n","      <td>0.039151</td>\n","      <td>0.036317</td>\n","      <td>0.037540</td>\n","      <td>0.047838</td>\n","      <td>0.031877</td>\n","      <td>0.038163</td>\n","      <td>0.039022</td>\n","      <td>0.037780</td>\n","      <td>0.029666</td>\n","      <td>0.045057</td>\n","      <td>0.033834</td>\n","      <td>0.039320</td>\n","      <td>0.039902</td>\n","      <td>0.044196</td>\n","      <td>0.033762</td>\n","      <td>0.043657</td>\n","      <td>0.045517</td>\n","      <td>0.034513</td>\n","      <td>0.033318</td>\n","      <td>0.036002</td>\n","      <td>0.039627</td>\n","      <td>0.045321</td>\n","      <td>0.041871</td>\n","      <td>0.035925</td>\n","      <td>0.037507</td>\n","      <td>0.045871</td>\n","      <td>10.812359</td>\n","      <td>9.036426</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.500000</td>\n","      <td>0.000000</td>\n","      <td>0.220736</td>\n","      <td>0.386861</td>\n","      <td>0.408000</td>\n","      <td>0.242754</td>\n","      <td>0.228972</td>\n","      <td>0.245902</td>\n","      <td>0.230769</td>\n","      <td>0.571816</td>\n","      <td>0.145762</td>\n","      <td>0.107252</td>\n","      <td>0.091931</td>\n","      <td>0.113990</td>\n","      <td>0.265941</td>\n","      <td>0.280532</td>\n","      <td>0.324501</td>\n","      <td>0.430862</td>\n","      <td>0.377935</td>\n","      <td>0.387450</td>\n","      <td>0.398253</td>\n","      <td>0.268717</td>\n","      <td>0.371063</td>\n","      <td>0.388484</td>\n","      <td>0.415418</td>\n","      <td>0.364886</td>\n","      <td>0.354959</td>\n","      <td>0.407442</td>\n","      <td>0.366554</td>\n","      <td>0.395420</td>\n","      <td>0.331553</td>\n","      <td>0.422746</td>\n","      <td>0.408808</td>\n","      <td>0.412807</td>\n","      <td>0.463294</td>\n","      <td>0.345775</td>\n","      <td>0.396314</td>\n","      <td>0.434573</td>\n","      <td>0.445521</td>\n","      <td>0.461860</td>\n","      <td>...</td>\n","      <td>0.484608</td>\n","      <td>0.446572</td>\n","      <td>0.477955</td>\n","      <td>0.386564</td>\n","      <td>0.433704</td>\n","      <td>0.426391</td>\n","      <td>0.448555</td>\n","      <td>0.438482</td>\n","      <td>0.480351</td>\n","      <td>0.467746</td>\n","      <td>0.449761</td>\n","      <td>0.413153</td>\n","      <td>0.450947</td>\n","      <td>0.424110</td>\n","      <td>0.440159</td>\n","      <td>0.464614</td>\n","      <td>0.457611</td>\n","      <td>0.464922</td>\n","      <td>0.444161</td>\n","      <td>0.485486</td>\n","      <td>0.401962</td>\n","      <td>0.484608</td>\n","      <td>0.374363</td>\n","      <td>0.476175</td>\n","      <td>0.426426</td>\n","      <td>0.461173</td>\n","      <td>0.480024</td>\n","      <td>0.439899</td>\n","      <td>0.477705</td>\n","      <td>0.396186</td>\n","      <td>0.460970</td>\n","      <td>0.435488</td>\n","      <td>0.462772</td>\n","      <td>0.485394</td>\n","      <td>0.449721</td>\n","      <td>0.417404</td>\n","      <td>0.419449</td>\n","      <td>0.471431</td>\n","      <td>4.040000</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.671053</td>\n","      <td>1.000000</td>\n","      <td>0.266388</td>\n","      <td>0.437956</td>\n","      <td>0.472000</td>\n","      <td>0.278986</td>\n","      <td>0.275701</td>\n","      <td>0.295082</td>\n","      <td>0.282051</td>\n","      <td>0.607046</td>\n","      <td>0.174518</td>\n","      <td>0.143003</td>\n","      <td>0.111338</td>\n","      <td>0.235946</td>\n","      <td>0.414156</td>\n","      <td>0.349070</td>\n","      <td>0.381126</td>\n","      <td>0.492161</td>\n","      <td>0.436467</td>\n","      <td>0.459334</td>\n","      <td>0.465659</td>\n","      <td>0.309602</td>\n","      <td>0.418028</td>\n","      <td>0.440322</td>\n","      <td>0.446652</td>\n","      <td>0.417332</td>\n","      <td>0.390567</td>\n","      <td>0.448180</td>\n","      <td>0.411485</td>\n","      <td>0.450213</td>\n","      <td>0.377327</td>\n","      <td>0.457831</td>\n","      <td>0.465278</td>\n","      <td>0.469591</td>\n","      <td>0.498781</td>\n","      <td>0.386092</td>\n","      <td>0.430826</td>\n","      <td>0.477434</td>\n","      <td>0.484301</td>\n","      <td>0.499109</td>\n","      <td>...</td>\n","      <td>0.492958</td>\n","      <td>0.454800</td>\n","      <td>0.485801</td>\n","      <td>0.393884</td>\n","      <td>0.442997</td>\n","      <td>0.434644</td>\n","      <td>0.455761</td>\n","      <td>0.445441</td>\n","      <td>0.487467</td>\n","      <td>0.476243</td>\n","      <td>0.459752</td>\n","      <td>0.419719</td>\n","      <td>0.458328</td>\n","      <td>0.431311</td>\n","      <td>0.447707</td>\n","      <td>0.474401</td>\n","      <td>0.464384</td>\n","      <td>0.471902</td>\n","      <td>0.451163</td>\n","      <td>0.493228</td>\n","      <td>0.408273</td>\n","      <td>0.493790</td>\n","      <td>0.380991</td>\n","      <td>0.483777</td>\n","      <td>0.434256</td>\n","      <td>0.469893</td>\n","      <td>0.486536</td>\n","      <td>0.448161</td>\n","      <td>0.485961</td>\n","      <td>0.402764</td>\n","      <td>0.467614</td>\n","      <td>0.443086</td>\n","      <td>0.470368</td>\n","      <td>0.494293</td>\n","      <td>0.457959</td>\n","      <td>0.424076</td>\n","      <td>0.426816</td>\n","      <td>0.480293</td>\n","      <td>6.910000</td>\n","      <td>12.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.828947</td>\n","      <td>1.000000</td>\n","      <td>0.297659</td>\n","      <td>0.496350</td>\n","      <td>0.528000</td>\n","      <td>0.326087</td>\n","      <td>0.322430</td>\n","      <td>0.360656</td>\n","      <td>0.358974</td>\n","      <td>0.643360</td>\n","      <td>0.206658</td>\n","      <td>0.186925</td>\n","      <td>0.136874</td>\n","      <td>0.384646</td>\n","      <td>0.517535</td>\n","      <td>0.449899</td>\n","      <td>0.467114</td>\n","      <td>0.568168</td>\n","      <td>0.511402</td>\n","      <td>0.521056</td>\n","      <td>0.517521</td>\n","      <td>0.391259</td>\n","      <td>0.497101</td>\n","      <td>0.484994</td>\n","      <td>0.506157</td>\n","      <td>0.480755</td>\n","      <td>0.446613</td>\n","      <td>0.513969</td>\n","      <td>0.455596</td>\n","      <td>0.485496</td>\n","      <td>0.412040</td>\n","      <td>0.514318</td>\n","      <td>0.520719</td>\n","      <td>0.514803</td>\n","      <td>0.550257</td>\n","      <td>0.440383</td>\n","      <td>0.477339</td>\n","      <td>0.522524</td>\n","      <td>0.535303</td>\n","      <td>0.531225</td>\n","      <td>...</td>\n","      <td>0.501481</td>\n","      <td>0.462958</td>\n","      <td>0.493355</td>\n","      <td>0.400363</td>\n","      <td>0.451416</td>\n","      <td>0.443052</td>\n","      <td>0.462025</td>\n","      <td>0.452996</td>\n","      <td>0.494892</td>\n","      <td>0.484777</td>\n","      <td>0.468801</td>\n","      <td>0.425922</td>\n","      <td>0.466054</td>\n","      <td>0.438301</td>\n","      <td>0.454966</td>\n","      <td>0.483655</td>\n","      <td>0.470241</td>\n","      <td>0.478948</td>\n","      <td>0.458877</td>\n","      <td>0.500660</td>\n","      <td>0.413479</td>\n","      <td>0.502334</td>\n","      <td>0.387640</td>\n","      <td>0.491620</td>\n","      <td>0.441950</td>\n","      <td>0.478439</td>\n","      <td>0.492600</td>\n","      <td>0.458063</td>\n","      <td>0.495542</td>\n","      <td>0.409278</td>\n","      <td>0.473749</td>\n","      <td>0.449918</td>\n","      <td>0.478174</td>\n","      <td>0.502929</td>\n","      <td>0.466078</td>\n","      <td>0.431089</td>\n","      <td>0.434002</td>\n","      <td>0.489373</td>\n","      <td>11.930000</td>\n","      <td>20.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>294.660000</td>\n","      <td>30.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 1451 columns</p>\n","</div>"],"text/plain":["                age        gender  ...  length_of_stay_hospital  days_to_death\n","count  48866.000000  48866.000000  ...             48866.000000   21444.000000\n","mean       0.650590      0.562129  ...                 9.990334      12.628474\n","std        0.228188      0.496130  ...                10.812359       9.036426\n","min        0.000000      0.000000  ...                 0.000000      -3.000000\n","25%        0.500000      0.000000  ...                 4.040000       5.000000\n","50%        0.671053      1.000000  ...                 6.910000      12.000000\n","75%        0.828947      1.000000  ...                11.930000      20.000000\n","max        1.000000      1.000000  ...               294.660000      30.000000\n","\n","[8 rows x 1451 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"54fe929f"},"source":["## Examine the class label imbalance:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"722a2072","executionInfo":{"status":"ok","timestamp":1622314602557,"user_tz":-120,"elapsed":12,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"6ce1fbce-7532-4d33-b5d6-aa139abbb6e7"},"source":["neg, pos = np.bincount(df['died_in_hospital'])\n","total = neg + pos\n","print(f'Examples:\\n    Total: {total}\\n    Positive: {pos} ({100 * pos / total:.2f}% of total)\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Examples:\n","    Total: 48866\n","    Positive: 5612 (11.48% of total)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G05Oi-SN7zG5"},"source":["### Pop unnecessary labels:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuTkDzLB2x7M","executionInfo":{"status":"ok","timestamp":1622314602900,"user_tz":-120,"elapsed":350,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"8d6fab93-572f-4468-8284-3b1dcc2a8d0a"},"source":["df.pop(\"days_to_death\")\n","df.pop(\"length_of_stay_hospital\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        10.61\n","1        60.01\n","2         6.33\n","3         6.02\n","4         2.01\n","         ...  \n","48861    15.87\n","48862     7.86\n","48863    13.24\n","48864     3.14\n","48865     2.82\n","Name: length_of_stay_hospital, Length: 48866, dtype: float64"]},"metadata":{"tags":[]},"execution_count":206}]},{"cell_type":"markdown","metadata":{"id":"6407c31c"},"source":["## Split data:"]},{"cell_type":"code","metadata":{"id":"edd424ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622314604615,"user_tz":-120,"elapsed":1718,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"e205dd1a-62d4-4034-8dfd-d3986cd34852"},"source":["print(df.columns[:20])\n","print(df.columns[-5:])\n","\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","train_df, val_df = train_test_split(df, test_size=0.2)\n","\n","train_labels = np.array(train_df.pop('died_in_hospital')).astype('float32')\n","bool_train_labels = train_labels != 0\n","val_labels = np.array(val_df.pop('died_in_hospital')).astype('float32')\n","test_labels = np.array(test_df.pop('died_in_hospital')).astype('float32')\n","\n","train_features = np.array(train_df)\n","val_features = np.array(val_df)\n","test_features = np.array(test_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Index([          'age',        'gender',        'weight',   'meanbp_mean',\n","          'meanbp_min',    'meanbp_max',  'resprate_min',  'resprate_max',\n","       'resprate_mean',    'tempc_mean',   'glucose_min',   'glucose_max',\n","        'glucose_mean',               0,               1,               2,\n","                     3,               4,               5,               6],\n","      dtype='object')\n","Index([1432, 1433, 1434, 1435, 'died_in_hospital'], dtype='object')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b8d8283","executionInfo":{"status":"ok","timestamp":1622314607380,"user_tz":-120,"elapsed":2770,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"78c52205-c6ff-4f6c-867f-043a22fc4225"},"source":["scaler = StandardScaler()\n","train_features = scaler.fit_transform(train_features)\n","\n","val_features = scaler.transform(val_features)\n","test_features = scaler.transform(test_features)\n","\n","train_features = np.clip(train_features, -5, 5)\n","val_features = np.clip(val_features, -5, 5)\n","test_features = np.clip(test_features, -5, 5)\n","\n","\n","print('Training labels shape:', train_labels.shape)\n","print('Validation labels shape:', val_labels.shape)\n","print('Test labels shape:', test_labels.shape)\n","\n","print('Training features shape:', train_features.shape)\n","print('Validation features shape:', val_features.shape)\n","print('Test features shape:', test_features.shape)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training labels shape: (39092,)\n","Validation labels shape: (9774,)\n","Test labels shape: (9774,)\n","Training features shape: (39092, 1449)\n","Validation features shape: (9774, 1449)\n","Test features shape: (9774, 1449)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6d7a26c3"},"source":["## Define the model and metrics:"]},{"cell_type":"code","metadata":{"id":"c742ab09"},"source":["METRICS = [\n","      keras.metrics.TruePositives(name='tp'),\n","      keras.metrics.FalsePositives(name='fp'),\n","      keras.metrics.TrueNegatives(name='tn'),\n","      keras.metrics.FalseNegatives(name='fn'), \n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","      keras.metrics.Precision(name='precision'),\n","      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","]\n","\n","def make_model(metrics=METRICS, output_bias=None):\n","    if output_bias is not None:\n","        output_bias = tf.keras.initializers.Constant(output_bias)\n","        \n","    model = keras.Sequential([\n","        keras.layers.Dense(layer1nodes, activation='relu', input_shape=(train_features.shape[-1],)),\n","        keras.layers.Dropout(0.5),\n","        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),\n","    ])\n","\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(lr=1e-3),\n","        loss=keras.losses.BinaryCrossentropy(),\n","        metrics=metrics)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3b256c0"},"source":["EPOCHS = 512\n","BATCH_SIZE = 2048\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_prc', \n","    verbose=1,\n","    patience=24,\n","    mode='max',\n","    restore_best_weights=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d05698ea","executionInfo":{"status":"ok","timestamp":1622314607382,"user_tz":-120,"elapsed":19,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"e725f802-da7c-4b88-a163-1801613d85cc"},"source":["initial_bias = np.log([pos/neg])\n","\n","model = make_model(output_bias=initial_bias)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_42 (Dense)             (None, 448)               649600    \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 448)               0         \n","_________________________________________________________________\n","dense_43 (Dense)             (None, 1)                 449       \n","=================================================================\n","Total params: 650,049\n","Trainable params: 650,049\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a89f0fba","executionInfo":{"status":"ok","timestamp":1622314607799,"user_tz":-120,"elapsed":422,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"cb2101a6-6766-4d97-ecaf-52d95842ecb3"},"source":["model.predict(train_features[-10:])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.12513283],\n","       [0.07756627],\n","       [0.11195478],\n","       [0.02580878],\n","       [0.20908916],\n","       [0.331079  ],\n","       [0.17120913],\n","       [0.24019024],\n","       [0.48413056],\n","       [0.10763434]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":212}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edc9dd1c","executionInfo":{"status":"ok","timestamp":1622314610334,"user_tz":-120,"elapsed":2538,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"20068321-142f-4f49-c182-c90e700eec89"},"source":["results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n","print(\"Loss: {:0.4f}\".format(results[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss: 0.4107\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6b47ad5e"},"source":["### Save initial Biases for better comparison:"]},{"cell_type":"code","metadata":{"id":"37683346"},"source":["initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1da17ece"},"source":["# Train model:"]},{"cell_type":"code","metadata":{"id":"RasBzu6ZLGEs","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1622314610337,"user_tz":-120,"elapsed":14,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"00fed7d9-5c6c-4e94-ae03-a474530ee3c5"},"source":["\"\"\"\n","train_features_tensor = tf.convert_to_tensor(train_features, dtype=tf.int64)\n","train_labels_tensor = tf.convert_to_tensor(train_labels, dtype=tf.int64)\n","val_features_tensor = tf.convert_to_tensor(val_features, dtype=tf.int64)\n","val_labels_tensor = tf.convert_to_tensor(val_labels, dtype=tf.int64)\n","test_features_tensor = tf.convert_to_tensor(test_features, dtype=tf.int64)\n","test_labels_tensor = tf.convert_to_tensor(test_labels, dtype=tf.int64)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_features_tensor = tf.convert_to_tensor(train_features, dtype=tf.int64)\\ntrain_labels_tensor = tf.convert_to_tensor(train_labels, dtype=tf.int64)\\nval_features_tensor = tf.convert_to_tensor(val_features, dtype=tf.int64)\\nval_labels_tensor = tf.convert_to_tensor(val_labels, dtype=tf.int64)\\ntest_features_tensor = tf.convert_to_tensor(test_features, dtype=tf.int64)\\ntest_labels_tensor = tf.convert_to_tensor(test_labels, dtype=tf.int64)\\n'"]},"metadata":{"tags":[]},"execution_count":215}]},{"cell_type":"markdown","metadata":{"id":"bf392d70"},"source":["## Weighted Classes:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"303b2727","executionInfo":{"status":"ok","timestamp":1622314610339,"user_tz":-120,"elapsed":12,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"833d9f79-7f85-4914-be3b-9b21d2b7898f"},"source":["# Scaling by total/2 helps keep the loss to a similar magnitude.\n","# The sum of the weights of all examples stays the same.\n","weight_for_0 = (1 / neg)*(total)/2.0 \n","weight_for_1 = (1 / pos)*(total)/2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print('Weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Weight for class 1: {:.2f}'.format(weight_for_1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Weight for class 0: 0.56\n","Weight for class 1: 4.35\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3c6d033","executionInfo":{"status":"ok","timestamp":1622314697119,"user_tz":-120,"elapsed":86789,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"8c1dc4dd-f379-44ff-d7b2-61500f3f2856"},"source":["weighted_model = make_model()\n","\n","weighted_history = weighted_model.fit(\n","    train_features,\n","    train_labels,\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    callbacks=[early_stopping],\n","    validation_data=(val_features, val_labels),\n","    # The class weights go here\n","    class_weight=class_weight)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/512\n","20/20 [==============================] - 6s 180ms/step - loss: 0.7102 - tp: 3003.0000 - fp: 11536.0000 - tn: 57682.0000 - fn: 5963.0000 - accuracy: 0.7762 - precision: 0.2065 - recall: 0.3349 - auc: 0.5872 - prc: 0.2115 - val_loss: 0.5273 - val_tp: 951.0000 - val_fp: 2081.0000 - val_tn: 6564.0000 - val_fn: 178.0000 - val_accuracy: 0.7689 - val_precision: 0.3137 - val_recall: 0.8423 - val_auc: 0.8775 - val_prc: 0.5555\n","Epoch 2/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.4082 - tp: 3689.0000 - fp: 6002.0000 - tn: 28607.0000 - fn: 794.0000 - accuracy: 0.8262 - precision: 0.3807 - recall: 0.8229 - auc: 0.9000 - prc: 0.6053 - val_loss: 0.3610 - val_tp: 854.0000 - val_fp: 1136.0000 - val_tn: 7509.0000 - val_fn: 275.0000 - val_accuracy: 0.8556 - val_precision: 0.4291 - val_recall: 0.7564 - val_auc: 0.8898 - val_prc: 0.6006\n","Epoch 3/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.3265 - tp: 3901.0000 - fp: 4980.0000 - tn: 29629.0000 - fn: 582.0000 - accuracy: 0.8577 - precision: 0.4393 - recall: 0.8702 - auc: 0.9359 - prc: 0.6813 - val_loss: 0.3607 - val_tp: 876.0000 - val_fp: 1161.0000 - val_tn: 7484.0000 - val_fn: 253.0000 - val_accuracy: 0.8553 - val_precision: 0.4300 - val_recall: 0.7759 - val_auc: 0.8952 - val_prc: 0.6079\n","Epoch 4/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.2858 - tp: 3978.0000 - fp: 4244.0000 - tn: 30365.0000 - fn: 505.0000 - accuracy: 0.8785 - precision: 0.4838 - recall: 0.8874 - auc: 0.9507 - prc: 0.7226 - val_loss: 0.3415 - val_tp: 867.0000 - val_fp: 1091.0000 - val_tn: 7554.0000 - val_fn: 262.0000 - val_accuracy: 0.8616 - val_precision: 0.4428 - val_recall: 0.7679 - val_auc: 0.8992 - val_prc: 0.6202\n","Epoch 5/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.2621 - tp: 4083.0000 - fp: 4127.0000 - tn: 30482.0000 - fn: 400.0000 - accuracy: 0.8842 - precision: 0.4973 - recall: 0.9108 - auc: 0.9583 - prc: 0.7525 - val_loss: 0.3316 - val_tp: 851.0000 - val_fp: 1027.0000 - val_tn: 7618.0000 - val_fn: 278.0000 - val_accuracy: 0.8665 - val_precision: 0.4531 - val_recall: 0.7538 - val_auc: 0.8993 - val_prc: 0.6202\n","Epoch 6/512\n","20/20 [==============================] - 2s 117ms/step - loss: 0.2398 - tp: 4086.0000 - fp: 3503.0000 - tn: 31106.0000 - fn: 397.0000 - accuracy: 0.9002 - precision: 0.5384 - recall: 0.9114 - auc: 0.9648 - prc: 0.7711 - val_loss: 0.3264 - val_tp: 838.0000 - val_fp: 1008.0000 - val_tn: 7637.0000 - val_fn: 291.0000 - val_accuracy: 0.8671 - val_precision: 0.4540 - val_recall: 0.7422 - val_auc: 0.9017 - val_prc: 0.6243\n","Epoch 7/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.2186 - tp: 4164.0000 - fp: 3393.0000 - tn: 31216.0000 - fn: 319.0000 - accuracy: 0.9050 - precision: 0.5510 - recall: 0.9288 - auc: 0.9706 - prc: 0.8018 - val_loss: 0.3103 - val_tp: 818.0000 - val_fp: 884.0000 - val_tn: 7761.0000 - val_fn: 311.0000 - val_accuracy: 0.8777 - val_precision: 0.4806 - val_recall: 0.7245 - val_auc: 0.8999 - val_prc: 0.6225\n","Epoch 8/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.2027 - tp: 4179.0000 - fp: 2991.0000 - tn: 31618.0000 - fn: 304.0000 - accuracy: 0.9157 - precision: 0.5828 - recall: 0.9322 - auc: 0.9746 - prc: 0.8229 - val_loss: 0.3184 - val_tp: 831.0000 - val_fp: 924.0000 - val_tn: 7721.0000 - val_fn: 298.0000 - val_accuracy: 0.8750 - val_precision: 0.4735 - val_recall: 0.7360 - val_auc: 0.9000 - val_prc: 0.6192\n","Epoch 9/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.1858 - tp: 4251.0000 - fp: 2841.0000 - tn: 31768.0000 - fn: 232.0000 - accuracy: 0.9214 - precision: 0.5994 - recall: 0.9482 - auc: 0.9786 - prc: 0.8468 - val_loss: 0.3087 - val_tp: 814.0000 - val_fp: 845.0000 - val_tn: 7800.0000 - val_fn: 315.0000 - val_accuracy: 0.8813 - val_precision: 0.4907 - val_recall: 0.7210 - val_auc: 0.8986 - val_prc: 0.6175\n","Epoch 10/512\n","20/20 [==============================] - 2s 117ms/step - loss: 0.1760 - tp: 4257.0000 - fp: 2725.0000 - tn: 31884.0000 - fn: 226.0000 - accuracy: 0.9245 - precision: 0.6097 - recall: 0.9496 - auc: 0.9807 - prc: 0.8543 - val_loss: 0.3044 - val_tp: 800.0000 - val_fp: 802.0000 - val_tn: 7843.0000 - val_fn: 329.0000 - val_accuracy: 0.8843 - val_precision: 0.4994 - val_recall: 0.7086 - val_auc: 0.8989 - val_prc: 0.6219\n","Epoch 11/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.1644 - tp: 4259.0000 - fp: 2483.0000 - tn: 32126.0000 - fn: 224.0000 - accuracy: 0.9308 - precision: 0.6317 - recall: 0.9500 - auc: 0.9830 - prc: 0.8687 - val_loss: 0.3062 - val_tp: 808.0000 - val_fp: 781.0000 - val_tn: 7864.0000 - val_fn: 321.0000 - val_accuracy: 0.8873 - val_precision: 0.5085 - val_recall: 0.7157 - val_auc: 0.8980 - val_prc: 0.6250\n","Epoch 12/512\n","20/20 [==============================] - 2s 117ms/step - loss: 0.1558 - tp: 4301.0000 - fp: 2388.0000 - tn: 32221.0000 - fn: 182.0000 - accuracy: 0.9343 - precision: 0.6430 - recall: 0.9594 - auc: 0.9845 - prc: 0.8797 - val_loss: 0.3055 - val_tp: 799.0000 - val_fp: 763.0000 - val_tn: 7882.0000 - val_fn: 330.0000 - val_accuracy: 0.8882 - val_precision: 0.5115 - val_recall: 0.7077 - val_auc: 0.8957 - val_prc: 0.6163\n","Epoch 13/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.1440 - tp: 4316.0000 - fp: 2162.0000 - tn: 32447.0000 - fn: 167.0000 - accuracy: 0.9404 - precision: 0.6663 - recall: 0.9627 - auc: 0.9868 - prc: 0.8956 - val_loss: 0.3080 - val_tp: 793.0000 - val_fp: 740.0000 - val_tn: 7905.0000 - val_fn: 336.0000 - val_accuracy: 0.8899 - val_precision: 0.5173 - val_recall: 0.7024 - val_auc: 0.8965 - val_prc: 0.6127\n","Epoch 14/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.1364 - tp: 4353.0000 - fp: 2139.0000 - tn: 32470.0000 - fn: 130.0000 - accuracy: 0.9420 - precision: 0.6705 - recall: 0.9710 - auc: 0.9880 - prc: 0.9033 - val_loss: 0.3027 - val_tp: 760.0000 - val_fp: 680.0000 - val_tn: 7965.0000 - val_fn: 369.0000 - val_accuracy: 0.8927 - val_precision: 0.5278 - val_recall: 0.6732 - val_auc: 0.8947 - val_prc: 0.6115\n","Epoch 15/512\n","20/20 [==============================] - 2s 117ms/step - loss: 0.1290 - tp: 4329.0000 - fp: 1931.0000 - tn: 32678.0000 - fn: 154.0000 - accuracy: 0.9467 - precision: 0.6915 - recall: 0.9656 - auc: 0.9893 - prc: 0.9126 - val_loss: 0.3073 - val_tp: 764.0000 - val_fp: 704.0000 - val_tn: 7941.0000 - val_fn: 365.0000 - val_accuracy: 0.8906 - val_precision: 0.5204 - val_recall: 0.6767 - val_auc: 0.8951 - val_prc: 0.6173\n","Epoch 16/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.1216 - tp: 4375.0000 - fp: 1935.0000 - tn: 32674.0000 - fn: 108.0000 - accuracy: 0.9477 - precision: 0.6933 - recall: 0.9759 - auc: 0.9904 - prc: 0.9200 - val_loss: 0.3037 - val_tp: 752.0000 - val_fp: 650.0000 - val_tn: 7995.0000 - val_fn: 377.0000 - val_accuracy: 0.8949 - val_precision: 0.5364 - val_recall: 0.6661 - val_auc: 0.8935 - val_prc: 0.6163\n","Epoch 17/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.1166 - tp: 4379.0000 - fp: 1792.0000 - tn: 32817.0000 - fn: 104.0000 - accuracy: 0.9515 - precision: 0.7096 - recall: 0.9768 - auc: 0.9912 - prc: 0.9265 - val_loss: 0.3093 - val_tp: 740.0000 - val_fp: 663.0000 - val_tn: 7982.0000 - val_fn: 389.0000 - val_accuracy: 0.8924 - val_precision: 0.5274 - val_recall: 0.6554 - val_auc: 0.8905 - val_prc: 0.6139\n","Epoch 18/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.1107 - tp: 4380.0000 - fp: 1714.0000 - tn: 32895.0000 - fn: 103.0000 - accuracy: 0.9535 - precision: 0.7187 - recall: 0.9770 - auc: 0.9919 - prc: 0.9284 - val_loss: 0.3090 - val_tp: 750.0000 - val_fp: 638.0000 - val_tn: 8007.0000 - val_fn: 379.0000 - val_accuracy: 0.8959 - val_precision: 0.5403 - val_recall: 0.6643 - val_auc: 0.8923 - val_prc: 0.6101\n","Epoch 19/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.1019 - tp: 4398.0000 - fp: 1583.0000 - tn: 33026.0000 - fn: 85.0000 - accuracy: 0.9573 - precision: 0.7353 - recall: 0.9810 - auc: 0.9933 - prc: 0.9421 - val_loss: 0.3087 - val_tp: 728.0000 - val_fp: 607.0000 - val_tn: 8038.0000 - val_fn: 401.0000 - val_accuracy: 0.8969 - val_precision: 0.5453 - val_recall: 0.6448 - val_auc: 0.8902 - val_prc: 0.6097\n","Epoch 20/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0973 - tp: 4393.0000 - fp: 1416.0000 - tn: 33193.0000 - fn: 90.0000 - accuracy: 0.9615 - precision: 0.7562 - recall: 0.9799 - auc: 0.9939 - prc: 0.9488 - val_loss: 0.3147 - val_tp: 755.0000 - val_fp: 636.0000 - val_tn: 8009.0000 - val_fn: 374.0000 - val_accuracy: 0.8967 - val_precision: 0.5428 - val_recall: 0.6687 - val_auc: 0.8916 - val_prc: 0.6072\n","Epoch 21/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0906 - tp: 4421.0000 - fp: 1402.0000 - tn: 33207.0000 - fn: 62.0000 - accuracy: 0.9625 - precision: 0.7592 - recall: 0.9862 - auc: 0.9948 - prc: 0.9572 - val_loss: 0.3106 - val_tp: 718.0000 - val_fp: 583.0000 - val_tn: 8062.0000 - val_fn: 411.0000 - val_accuracy: 0.8983 - val_precision: 0.5519 - val_recall: 0.6360 - val_auc: 0.8901 - val_prc: 0.6120\n","Epoch 22/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0854 - tp: 4414.0000 - fp: 1278.0000 - tn: 33331.0000 - fn: 69.0000 - accuracy: 0.9655 - precision: 0.7755 - recall: 0.9846 - auc: 0.9952 - prc: 0.9568 - val_loss: 0.3139 - val_tp: 707.0000 - val_fp: 555.0000 - val_tn: 8090.0000 - val_fn: 422.0000 - val_accuracy: 0.9000 - val_precision: 0.5602 - val_recall: 0.6262 - val_auc: 0.8884 - val_prc: 0.6072\n","Epoch 23/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0799 - tp: 4415.0000 - fp: 1272.0000 - tn: 33337.0000 - fn: 68.0000 - accuracy: 0.9657 - precision: 0.7763 - recall: 0.9848 - auc: 0.9959 - prc: 0.9651 - val_loss: 0.3095 - val_tp: 715.0000 - val_fp: 547.0000 - val_tn: 8098.0000 - val_fn: 414.0000 - val_accuracy: 0.9017 - val_precision: 0.5666 - val_recall: 0.6333 - val_auc: 0.8905 - val_prc: 0.6148\n","Epoch 24/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0790 - tp: 4425.0000 - fp: 1135.0000 - tn: 33474.0000 - fn: 58.0000 - accuracy: 0.9695 - precision: 0.7959 - recall: 0.9871 - auc: 0.9958 - prc: 0.9636 - val_loss: 0.3150 - val_tp: 714.0000 - val_fp: 555.0000 - val_tn: 8090.0000 - val_fn: 415.0000 - val_accuracy: 0.9008 - val_precision: 0.5626 - val_recall: 0.6324 - val_auc: 0.8903 - val_prc: 0.6084\n","Epoch 25/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.0704 - tp: 4434.0000 - fp: 1073.0000 - tn: 33536.0000 - fn: 49.0000 - accuracy: 0.9713 - precision: 0.8052 - recall: 0.9891 - auc: 0.9969 - prc: 0.9747 - val_loss: 0.3156 - val_tp: 700.0000 - val_fp: 531.0000 - val_tn: 8114.0000 - val_fn: 429.0000 - val_accuracy: 0.9018 - val_precision: 0.5686 - val_recall: 0.6200 - val_auc: 0.8876 - val_prc: 0.6113\n","Epoch 26/512\n","20/20 [==============================] - 2s 120ms/step - loss: 0.0713 - tp: 4430.0000 - fp: 1096.0000 - tn: 33513.0000 - fn: 53.0000 - accuracy: 0.9706 - precision: 0.8017 - recall: 0.9882 - auc: 0.9966 - prc: 0.9714 - val_loss: 0.3241 - val_tp: 712.0000 - val_fp: 555.0000 - val_tn: 8090.0000 - val_fn: 417.0000 - val_accuracy: 0.9006 - val_precision: 0.5620 - val_recall: 0.6306 - val_auc: 0.8867 - val_prc: 0.6121\n","Epoch 27/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.0690 - tp: 4431.0000 - fp: 1118.0000 - tn: 33491.0000 - fn: 52.0000 - accuracy: 0.9701 - precision: 0.7985 - recall: 0.9884 - auc: 0.9968 - prc: 0.9718 - val_loss: 0.3241 - val_tp: 702.0000 - val_fp: 528.0000 - val_tn: 8117.0000 - val_fn: 427.0000 - val_accuracy: 0.9023 - val_precision: 0.5707 - val_recall: 0.6218 - val_auc: 0.8859 - val_prc: 0.6079\n","Epoch 28/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0671 - tp: 4444.0000 - fp: 1014.0000 - tn: 33595.0000 - fn: 39.0000 - accuracy: 0.9731 - precision: 0.8142 - recall: 0.9913 - auc: 0.9969 - prc: 0.9724 - val_loss: 0.3300 - val_tp: 683.0000 - val_fp: 523.0000 - val_tn: 8122.0000 - val_fn: 446.0000 - val_accuracy: 0.9009 - val_precision: 0.5663 - val_recall: 0.6050 - val_auc: 0.8861 - val_prc: 0.6002\n","Epoch 29/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0656 - tp: 4434.0000 - fp: 1002.0000 - tn: 33607.0000 - fn: 49.0000 - accuracy: 0.9731 - precision: 0.8157 - recall: 0.9891 - auc: 0.9970 - prc: 0.9745 - val_loss: 0.3351 - val_tp: 687.0000 - val_fp: 524.0000 - val_tn: 8121.0000 - val_fn: 442.0000 - val_accuracy: 0.9012 - val_precision: 0.5673 - val_recall: 0.6085 - val_auc: 0.8832 - val_prc: 0.5993\n","Epoch 30/512\n","20/20 [==============================] - 2s 120ms/step - loss: 0.0629 - tp: 4425.0000 - fp: 885.0000 - tn: 33724.0000 - fn: 58.0000 - accuracy: 0.9759 - precision: 0.8333 - recall: 0.9871 - auc: 0.9975 - prc: 0.9794 - val_loss: 0.3383 - val_tp: 699.0000 - val_fp: 531.0000 - val_tn: 8114.0000 - val_fn: 430.0000 - val_accuracy: 0.9017 - val_precision: 0.5683 - val_recall: 0.6191 - val_auc: 0.8816 - val_prc: 0.6021\n","Epoch 31/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0600 - tp: 4441.0000 - fp: 949.0000 - tn: 33660.0000 - fn: 42.0000 - accuracy: 0.9746 - precision: 0.8239 - recall: 0.9906 - auc: 0.9977 - prc: 0.9814 - val_loss: 0.3385 - val_tp: 686.0000 - val_fp: 510.0000 - val_tn: 8135.0000 - val_fn: 443.0000 - val_accuracy: 0.9025 - val_precision: 0.5736 - val_recall: 0.6076 - val_auc: 0.8800 - val_prc: 0.6008\n","Epoch 32/512\n","20/20 [==============================] - 2s 117ms/step - loss: 0.0567 - tp: 4436.0000 - fp: 810.0000 - tn: 33799.0000 - fn: 47.0000 - accuracy: 0.9781 - precision: 0.8456 - recall: 0.9895 - auc: 0.9980 - prc: 0.9826 - val_loss: 0.3475 - val_tp: 695.0000 - val_fp: 531.0000 - val_tn: 8114.0000 - val_fn: 434.0000 - val_accuracy: 0.9013 - val_precision: 0.5669 - val_recall: 0.6156 - val_auc: 0.8792 - val_prc: 0.5955\n","Epoch 33/512\n","20/20 [==============================] - 2s 119ms/step - loss: 0.0532 - tp: 4453.0000 - fp: 832.0000 - tn: 33777.0000 - fn: 30.0000 - accuracy: 0.9779 - precision: 0.8426 - recall: 0.9933 - auc: 0.9982 - prc: 0.9826 - val_loss: 0.3450 - val_tp: 682.0000 - val_fp: 497.0000 - val_tn: 8148.0000 - val_fn: 447.0000 - val_accuracy: 0.9034 - val_precision: 0.5785 - val_recall: 0.6041 - val_auc: 0.8769 - val_prc: 0.5967\n","Epoch 34/512\n","20/20 [==============================] - 2s 118ms/step - loss: 0.0511 - tp: 4449.0000 - fp: 754.0000 - tn: 33855.0000 - fn: 34.0000 - accuracy: 0.9798 - precision: 0.8551 - recall: 0.9924 - auc: 0.9983 - prc: 0.9864 - val_loss: 0.3473 - val_tp: 672.0000 - val_fp: 475.0000 - val_tn: 8170.0000 - val_fn: 457.0000 - val_accuracy: 0.9046 - val_precision: 0.5859 - val_recall: 0.5952 - val_auc: 0.8803 - val_prc: 0.5985\n","Epoch 35/512\n","20/20 [==============================] - 2s 121ms/step - loss: 0.0518 - tp: 4452.0000 - fp: 792.0000 - tn: 33817.0000 - fn: 31.0000 - accuracy: 0.9789 - precision: 0.8490 - recall: 0.9931 - auc: 0.9981 - prc: 0.9808 - val_loss: 0.3464 - val_tp: 680.0000 - val_fp: 469.0000 - val_tn: 8176.0000 - val_fn: 449.0000 - val_accuracy: 0.9061 - val_precision: 0.5918 - val_recall: 0.6023 - val_auc: 0.8801 - val_prc: 0.6051\n","Restoring model weights from the end of the best epoch.\n","Epoch 00035: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9eafb1f2"},"source":["## Resampled data:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c79eae6d","executionInfo":{"status":"ok","timestamp":1622314698379,"user_tz":-120,"elapsed":1273,"user":{"displayName":"Julius Wachlin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghocx-xoUa07R5W0E0D5PY2L5tRof1hzp6zidzE=s64","userId":"16487439078493893689"}},"outputId":"1a538645-eda7-4213-d582-c559b21e7797"},"source":["pos_features = train_features[bool_train_labels]\n","neg_features = train_features[~bool_train_labels]\n","\n","pos_labels = train_labels[bool_train_labels]\n","neg_labels = train_labels[~bool_train_labels]\n","\n","neg_features.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34609, 1449)"]},"metadata":{"tags":[]},"execution_count":218}]},{"cell_type":"code","metadata":{"id":"0f136e5d"},"source":["ids = np.arange(len(pos_features))\n","choices = np.random.choice(ids, len(neg_features))\n","\n","res_pos_features = pos_features[choices]\n","res_pos_labels = pos_labels[choices]\n","\n","res_pos_features.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5e07ca29"},"source":["resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n","resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n","\n","order = np.arange(len(resampled_labels))\n","np.random.shuffle(order)\n","resampled_features = resampled_features[order]\n","resampled_labels = resampled_labels[order]\n","\n","resampled_features.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb60a929"},"source":["BUFFER_SIZE = 100000\n","\n","def make_ds(features, labels):\n","    ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n","    ds = ds.shuffle(BUFFER_SIZE).repeat()\n","    return ds\n","\n","\"\"\"\n","pos_features_tensor = tf.convert_to_tensor(pos_features, dtype=tf.int64)\n","pos_labels_tensor = tf.convert_to_tensor(pos_labels, dtype=tf.int64)\n","\n","neg_features_tensor = tf.convert_to_tensor(neg_features, dtype=tf.int64)\n","neg_labels_tensor = tf.convert_to_tensor(neg_labels, dtype=tf.int64)\n","\"\"\"\n","\n","pos_ds = make_ds(pos_features, pos_labels)\n","neg_ds = make_ds(neg_features, neg_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2e2bdd37"},"source":["resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n","resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8e0a3331"},"source":["for features, label in resampled_ds.take(1):\n","    print(label.numpy().mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"486527a8"},"source":["resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n","resampled_steps_per_epoch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"69fc1e9c"},"source":["resampled_model = make_model()\n","\n","# Reset the bias to zero, since this dataset is balanced.\n","output_layer = resampled_model.layers[-1] \n","output_layer.bias.assign([0])\n","\n","val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n","val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n","\n","resampled_history = resampled_model.fit(\n","    resampled_ds,\n","    # These are not real epochs (added to avoid overfitting)\n","    steps_per_epoch=20,\n","    epochs=10*EPOCHS,\n","    callbacks=[early_stopping],\n","    validation_data=val_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54b239cb"},"source":["# Evaluate training history:\n","\n","- Accuracy is the percentage of examples correctly classified\n","- Precision is the percentage of predicted positives that were correctly classified\n","- Recall is the percentage of actual positives that were correctly classified\n","- AUC refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample.\n","- AUPRC refers to Area Under the Curve of the Precision-Recall Curve. This metric computes precision-recall pairs for different probability thresholds."]},{"cell_type":"code","metadata":{"id":"04b8ae41"},"source":["def plot_metrics(history, label, color):\n","    metrics = ['loss', 'prc', 'precision', 'recall']\n","    # metrics = ['tp', 'fp', 'tn', 'fn']\n","    for n, metric in enumerate(metrics):\n","        name = metric.replace(\"_\",\" \").capitalize()\n","        plt.subplot(2,2,n+1)\n","        plt.plot(history.epoch, history.history[metric], color=colors[color], label=label + ' Train')\n","        plt.plot(history.epoch, history.history['val_'+metric],\n","                 color=colors[color], linestyle=\"--\", label=label + ' Val')\n","        plt.xlabel('Epoch')\n","        plt.ylabel(name)\n","        if metric == 'loss':\n","            plt.ylim([0, plt.ylim()[1]])\n","        elif metric == 'auc':\n","            plt.ylim([0.8,1])\n","        elif metric in ['tp', 'fp', 'fn']:\n","            plt.ylim([0, pos])\n","        elif metric in ['tn']:\n","            plt.ylim([0, neg])\n","        else:\n","            plt.ylim([0,1])\n","\n","    plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6933c6a9"},"source":["plot_metrics(weighted_history, \"weighted\", 1)\n","plot_metrics(resampled_history, \"resampled\", 2)\n","\n","plt.savefig(f\"{model_path}/metrics_{model_name}.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e99f30a6"},"source":["## Evaluate classification:"]},{"cell_type":"code","metadata":{"id":"203486a8"},"source":["def plot_cm(labels, predictions, p=0.5):\n","    cm = confusion_matrix(labels, predictions > p)\n","    plt.figure(figsize=(5,5))\n","    sns.heatmap(cm, annot=True, fmt=\"d\")\n","    plt.title('Confusion matrix @{:.2f}'.format(p))\n","    plt.ylabel('Actual label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2747d2e"},"source":["train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n","test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8574d024"},"source":["weighted_results = weighted_model.evaluate(test_features, test_labels,\n","                                           batch_size=BATCH_SIZE, verbose=0)\n","for name, value in zip(weighted_model.metrics_names, weighted_results):\n","    print(name, ': ', value)\n","print()\n","\n","plot_cm(test_labels, test_predictions_weighted)\n","\n","plt.savefig(f\"{model_path}/weighted_classification_{model_name}.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9b8ab93"},"source":["train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\n","test_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"c4e8bb82"},"source":["resampled_results = resampled_model.evaluate(test_features, test_labels,\n","                                             batch_size=BATCH_SIZE, verbose=0)\n","for name, value in zip(resampled_model.metrics_names, resampled_results):\n","    print(name, ': ', value)\n","print()\n","\n","plot_cm(test_labels, test_predictions_resampled)\n","plt.savefig(f\"{model_path}/resampled_classification_{model_name}.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1c085c1"},"source":["## Plot the ROC (receiver operating characteristic) Curve:"]},{"cell_type":"code","metadata":{"id":"2960bb92"},"source":["def plot_roc(name, labels, predictions, **kwargs):\n","    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n","\n","    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n","    plt.xlabel('False positives [%]')\n","    plt.ylabel('True positives [%]')\n","    plt.xlim([-0.5,25])\n","    plt.ylim([75,100.5])\n","    plt.grid(True)\n","    ax = plt.gca()\n","    ax.set_aspect('equal')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f236bb3b"},"source":["plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n","plot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n","\n","plot_roc(\"Train Resampled\", train_labels, train_predictions_resampled, color=colors[2])\n","plot_roc(\"Test Resampled\", test_labels, test_predictions_resampled, color=colors[2], linestyle='--')\n","\n","plt.legend(loc='upper left')\n","plt.savefig(f\"{model_path}/roc_{model_name}.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5f5ad9cf"},"source":["## Plot the PRC (precision-recall curve)"]},{"cell_type":"code","metadata":{"id":"c6dfa776"},"source":["def plot_prc(name, labels, predictions, **kwargs):\n","    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n","\n","    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.grid(True)\n","    ax = plt.gca()\n","    ax.set_aspect('equal')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b670d5aa"},"source":["plot_prc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n","plot_prc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n","\n","plot_prc(\"Train Resampled\", train_labels, train_predictions_resampled, color=colors[2])\n","plot_prc(\"Test Resampled\", test_labels, test_predictions_resampled, color=colors[2], linestyle='--')\n","\n","plt.legend(loc='upper right')\n","plt.savefig(f\"{model_path}/prc_{model_name}.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dd88406"},"source":["weighted_model.save(f\"{model_path}/weighted_model_{model_name}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1s5u93c0AVmX"},"source":["resampled_model.save(f\"{model_path}/resampled_model_{model_name}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9bY0EevMJrb"},"source":[""],"execution_count":null,"outputs":[]}]}