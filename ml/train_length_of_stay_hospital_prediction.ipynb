{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-8bjaew5f because the default path (/home/juliuswa/installed/apache-tomcat-9.0.30/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "import pickle as pk\n",
    "from sklearn.decomposition import PCA as pca\n",
    "\n",
    "\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"95\"\n",
    "layer1nodes = 256\n",
    "prefix = \"losh\"\n",
    "\n",
    "data_path = \"../../RoboDocData\"\n",
    "\n",
    "df_path = f\"{data_path}/{df_name}\"\n",
    "\n",
    "model_name = f\"df{df_name}_{prefix}_n{layer1nodes}\"\n",
    "\n",
    "model_path = f\"{df_path}/{model_name}\"\n",
    "\n",
    "if path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{df_path}/dataframe_{df_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>heartrate_mean</th>\n",
       "      <th>heartrate_min</th>\n",
       "      <th>heartrate_max</th>\n",
       "      <th>meanbp_mean</th>\n",
       "      <th>meanbp_min</th>\n",
       "      <th>meanbp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>1433</th>\n",
       "      <th>1434</th>\n",
       "      <th>1435</th>\n",
       "      <th>1436</th>\n",
       "      <th>1437</th>\n",
       "      <th>length_of_stay_hospital</th>\n",
       "      <th>days_to_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>4.927600e+04</td>\n",
       "      <td>49276.000000</td>\n",
       "      <td>21266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.785158e-17</td>\n",
       "      <td>2.667635e-18</td>\n",
       "      <td>-2.447736e-17</td>\n",
       "      <td>-8.201177e-19</td>\n",
       "      <td>4.217748e-18</td>\n",
       "      <td>-2.703685e-17</td>\n",
       "      <td>4.866632e-18</td>\n",
       "      <td>1.292361e-17</td>\n",
       "      <td>-5.767861e-18</td>\n",
       "      <td>5.302827e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.092303e-18</td>\n",
       "      <td>-7.966857e-18</td>\n",
       "      <td>9.805363e-18</td>\n",
       "      <td>-1.103103e-17</td>\n",
       "      <td>6.660076e-18</td>\n",
       "      <td>-8.651791e-18</td>\n",
       "      <td>7.678464e-18</td>\n",
       "      <td>-4.181699e-18</td>\n",
       "      <td>10.001152</td>\n",
       "      <td>516.919261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>1.000010e+00</td>\n",
       "      <td>10.824429</td>\n",
       "      <td>750.269258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.851985e+00</td>\n",
       "      <td>-1.132784e+00</td>\n",
       "      <td>-3.679919e+00</td>\n",
       "      <td>-7.150134e+00</td>\n",
       "      <td>-3.551337e+00</td>\n",
       "      <td>-4.715110e+00</td>\n",
       "      <td>-3.556091e+00</td>\n",
       "      <td>-5.410569e+00</td>\n",
       "      <td>-4.293148e+00</td>\n",
       "      <td>-3.161874e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.044598e+01</td>\n",
       "      <td>-1.423567e+01</td>\n",
       "      <td>-1.254131e+01</td>\n",
       "      <td>-1.166184e+01</td>\n",
       "      <td>-8.771547e+00</td>\n",
       "      <td>-1.245394e+01</td>\n",
       "      <td>-1.092345e+01</td>\n",
       "      <td>-1.362189e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.602848e-01</td>\n",
       "      <td>-1.132784e+00</td>\n",
       "      <td>-6.305664e-01</td>\n",
       "      <td>-1.308840e-17</td>\n",
       "      <td>-7.229681e-01</td>\n",
       "      <td>-6.636825e-01</td>\n",
       "      <td>-6.937438e-01</td>\n",
       "      <td>-7.131228e-01</td>\n",
       "      <td>-5.493726e-01</td>\n",
       "      <td>-5.718688e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.307914e-01</td>\n",
       "      <td>-2.201078e-01</td>\n",
       "      <td>-1.900663e-01</td>\n",
       "      <td>-1.945371e-01</td>\n",
       "      <td>-2.193400e-01</td>\n",
       "      <td>-1.964945e-01</td>\n",
       "      <td>-2.140415e-01</td>\n",
       "      <td>-2.077441e-01</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.950739e-02</td>\n",
       "      <td>8.827810e-01</td>\n",
       "      <td>8.096634e-17</td>\n",
       "      <td>-1.308840e-17</td>\n",
       "      <td>-8.015685e-02</td>\n",
       "      <td>-6.248149e-02</td>\n",
       "      <td>-1.115714e-01</td>\n",
       "      <td>-9.270538e-02</td>\n",
       "      <td>1.349679e-16</td>\n",
       "      <td>-1.853008e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.542474e-02</td>\n",
       "      <td>-2.151379e-02</td>\n",
       "      <td>4.834280e-03</td>\n",
       "      <td>2.598291e-03</td>\n",
       "      <td>-9.215172e-03</td>\n",
       "      <td>2.073447e-04</td>\n",
       "      <td>-1.437202e-02</td>\n",
       "      <td>-1.388533e-02</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.816233e-01</td>\n",
       "      <td>8.827810e-01</td>\n",
       "      <td>3.858846e-01</td>\n",
       "      <td>-1.308840e-17</td>\n",
       "      <td>6.269355e-01</td>\n",
       "      <td>6.055197e-01</td>\n",
       "      <td>6.161441e-01</td>\n",
       "      <td>5.277120e-01</td>\n",
       "      <td>5.517378e-01</td>\n",
       "      <td>3.172375e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.692542e-01</td>\n",
       "      <td>1.802531e-01</td>\n",
       "      <td>1.904886e-01</td>\n",
       "      <td>1.836319e-01</td>\n",
       "      <td>1.849409e-01</td>\n",
       "      <td>2.104166e-01</td>\n",
       "      <td>1.817449e-01</td>\n",
       "      <td>1.797262e-01</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>722.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.531416e+00</td>\n",
       "      <td>8.827810e-01</td>\n",
       "      <td>1.013457e+01</td>\n",
       "      <td>3.581620e+01</td>\n",
       "      <td>5.062333e+00</td>\n",
       "      <td>4.680327e+00</td>\n",
       "      <td>8.572500e+00</td>\n",
       "      <td>6.731886e+00</td>\n",
       "      <td>4.882772e+00</td>\n",
       "      <td>7.507402e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.253282e+01</td>\n",
       "      <td>1.584002e+01</td>\n",
       "      <td>1.445355e+01</td>\n",
       "      <td>1.794241e+01</td>\n",
       "      <td>1.372316e+01</td>\n",
       "      <td>1.258050e+01</td>\n",
       "      <td>1.579031e+01</td>\n",
       "      <td>1.538091e+01</td>\n",
       "      <td>294.660000</td>\n",
       "      <td>4166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        gender        weight        height  heartrate_mean  \\\n",
       "count  4.927600e+04  4.927600e+04  4.927600e+04  4.927600e+04    4.927600e+04   \n",
       "mean   3.785158e-17  2.667635e-18 -2.447736e-17 -8.201177e-19    4.217748e-18   \n",
       "std    1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00    1.000010e+00   \n",
       "min   -2.851985e+00 -1.132784e+00 -3.679919e+00 -7.150134e+00   -3.551337e+00   \n",
       "25%   -6.602848e-01 -1.132784e+00 -6.305664e-01 -1.308840e-17   -7.229681e-01   \n",
       "50%    8.950739e-02  8.827810e-01  8.096634e-17 -1.308840e-17   -8.015685e-02   \n",
       "75%    7.816233e-01  8.827810e-01  3.858846e-01 -1.308840e-17    6.269355e-01   \n",
       "max    1.531416e+00  8.827810e-01  1.013457e+01  3.581620e+01    5.062333e+00   \n",
       "\n",
       "       heartrate_min  heartrate_max   meanbp_mean    meanbp_min    meanbp_max  \\\n",
       "count   4.927600e+04   4.927600e+04  4.927600e+04  4.927600e+04  4.927600e+04   \n",
       "mean   -2.703685e-17   4.866632e-18  1.292361e-17 -5.767861e-18  5.302827e-17   \n",
       "std     1.000010e+00   1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
       "min    -4.715110e+00  -3.556091e+00 -5.410569e+00 -4.293148e+00 -3.161874e+00   \n",
       "25%    -6.636825e-01  -6.937438e-01 -7.131228e-01 -5.493726e-01 -5.718688e-01   \n",
       "50%    -6.248149e-02  -1.115714e-01 -9.270538e-02  1.349679e-16 -1.853008e-01   \n",
       "75%     6.055197e-01   6.161441e-01  5.277120e-01  5.517378e-01  3.172375e-01   \n",
       "max     4.680327e+00   8.572500e+00  6.731886e+00  4.882772e+00  7.507402e+00   \n",
       "\n",
       "       ...          1430          1431          1432          1433  \\\n",
       "count  ...  4.927600e+04  4.927600e+04  4.927600e+04  4.927600e+04   \n",
       "mean   ... -6.092303e-18 -7.966857e-18  9.805363e-18 -1.103103e-17   \n",
       "std    ...  1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
       "min    ... -1.044598e+01 -1.423567e+01 -1.254131e+01 -1.166184e+01   \n",
       "25%    ... -2.307914e-01 -2.201078e-01 -1.900663e-01 -1.945371e-01   \n",
       "50%    ... -2.542474e-02 -2.151379e-02  4.834280e-03  2.598291e-03   \n",
       "75%    ...  1.692542e-01  1.802531e-01  1.904886e-01  1.836319e-01   \n",
       "max    ...  1.253282e+01  1.584002e+01  1.445355e+01  1.794241e+01   \n",
       "\n",
       "               1434          1435          1436          1437  \\\n",
       "count  4.927600e+04  4.927600e+04  4.927600e+04  4.927600e+04   \n",
       "mean   6.660076e-18 -8.651791e-18  7.678464e-18 -4.181699e-18   \n",
       "std    1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
       "min   -8.771547e+00 -1.245394e+01 -1.092345e+01 -1.362189e+01   \n",
       "25%   -2.193400e-01 -1.964945e-01 -2.140415e-01 -2.077441e-01   \n",
       "50%   -9.215172e-03  2.073447e-04 -1.437202e-02 -1.388533e-02   \n",
       "75%    1.849409e-01  2.104166e-01  1.817449e-01  1.797262e-01   \n",
       "max    1.372316e+01  1.258050e+01  1.579031e+01  1.538091e+01   \n",
       "\n",
       "       length_of_stay_hospital  days_to_death  \n",
       "count             49276.000000   21266.000000  \n",
       "mean                 10.001152     516.919261  \n",
       "std                  10.824429     750.269258  \n",
       "min                   0.000000       0.000000  \n",
       "25%                   4.040000      18.000000  \n",
       "50%                   6.920000     149.000000  \n",
       "75%                  11.950000     722.750000  \n",
       "max                 294.660000    4166.000000  \n",
       "\n",
       "[8 rows x 1505 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "49271    1\n",
       "49272    1\n",
       "49273    1\n",
       "49274    1\n",
       "49275    1\n",
       "Name: died_in_hospital, Length: 49276, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop('days_to_death')\n",
    "df.pop('died_in_hospital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 39421\n",
      "test: 9855\n"
     ]
    }
   ],
   "source": [
    "train_dataset = df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('length_of_stay_hospital')\n",
    "test_labels = test_features.pop('length_of_stay_hospital')\n",
    "\n",
    "print(f\"train: {len(train_labels)}\")\n",
    "print(f\"test: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None),\n",
    "    tf.keras.losses.MeanAbsolutePercentageError(name=\"mape\")\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(layer1nodes, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=METRICS)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='mape', \n",
    "    verbose=1,\n",
    "    patience=24,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 96886.0781 - mean_squared_error: 141.8110 - mape: 96836.9844 - val_loss: 251140.6719 - val_mean_squared_error: 135.8526 - val_mape: 250537.2031\n",
      "Epoch 2/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 687457.6875 - mean_squared_error: 127.4239 - mape: 687109.1250 - val_loss: 217655.8281 - val_mean_squared_error: 131.7246 - val_mape: 217132.7656\n",
      "Epoch 3/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 32432.3047 - mean_squared_error: 124.3402 - mape: 32415.8828 - val_loss: 151831.2969 - val_mean_squared_error: 126.9431 - val_mape: 151466.5469\n",
      "Epoch 4/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 916248.3750 - mean_squared_error: 120.0162 - mape: 915783.8125 - val_loss: 163209.8750 - val_mean_squared_error: 127.5043 - val_mape: 162817.7031\n",
      "Epoch 5/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 1733802.8750 - mean_squared_error: 118.5136 - mape: 1732923.7500 - val_loss: 248579.0469 - val_mean_squared_error: 122.1297 - val_mape: 247981.6250\n",
      "Epoch 6/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 913289.4375 - mean_squared_error: 117.6980 - mape: 912826.3750 - val_loss: 219174.4375 - val_mean_squared_error: 122.3893 - val_mape: 218647.6875\n",
      "Epoch 7/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 133193.6719 - mean_squared_error: 118.2942 - mape: 133126.1875 - val_loss: 154231.1250 - val_mean_squared_error: 128.1894 - val_mape: 153860.5000\n",
      "Epoch 8/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 1726148.7500 - mean_squared_error: 114.7705 - mape: 1725273.5000 - val_loss: 139090.8281 - val_mean_squared_error: 114.5007 - val_mape: 138756.6406\n",
      "Epoch 9/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 2707685.0000 - mean_squared_error: 115.9924 - mape: 2706312.0000 - val_loss: 215313.9375 - val_mean_squared_error: 124.5943 - val_mape: 214796.4844\n",
      "Epoch 10/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 3200243.7500 - mean_squared_error: 112.4415 - mape: 3198620.7500 - val_loss: 141871.6719 - val_mean_squared_error: 116.3000 - val_mape: 141530.8438\n",
      "Epoch 11/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 1324493.8750 - mean_squared_error: 125.1938 - mape: 1323822.2500 - val_loss: 191254.6719 - val_mean_squared_error: 125.5941 - val_mape: 190795.0781\n",
      "Epoch 12/64\n",
      "986/986 [==============================] - 3s 3ms/step - loss: 1165889.7500 - mean_squared_error: 111.1371 - mape: 1165298.5000 - val_loss: 148639.0469 - val_mean_squared_error: 107.2119 - val_mape: 148281.9688\n",
      "Epoch 13/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 1271211.8750 - mean_squared_error: 114.4572 - mape: 1270567.2500 - val_loss: 198589.3594 - val_mean_squared_error: 123.2187 - val_mape: 198112.1094\n",
      "Epoch 14/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 4137220.0000 - mean_squared_error: 113.1446 - mape: 4135122.0000 - val_loss: 140875.3750 - val_mean_squared_error: 110.0328 - val_mape: 140537.0156\n",
      "Epoch 15/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 4083596.2500 - mean_squared_error: 114.7078 - mape: 4081525.2500 - val_loss: 240391.7031 - val_mean_squared_error: 118.2704 - val_mape: 239814.0312\n",
      "Epoch 16/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 2636645.2500 - mean_squared_error: 109.5290 - mape: 2635308.2500 - val_loss: 144446.6250 - val_mean_squared_error: 111.3019 - val_mape: 144099.5938\n",
      "Epoch 17/64\n",
      "986/986 [==============================] - 5s 5ms/step - loss: 1623974.8750 - mean_squared_error: 118.6247 - mape: 1623151.5000 - val_loss: 243910.6094 - val_mean_squared_error: 139.9879 - val_mape: 243324.4375\n",
      "Epoch 18/64\n",
      "986/986 [==============================] - 5s 6ms/step - loss: 4847863.0000 - mean_squared_error: 127.0545 - mape: 4845404.5000 - val_loss: 137437.8125 - val_mean_squared_error: 101.9518 - val_mape: 137107.6562\n",
      "Epoch 19/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 3036322.2500 - mean_squared_error: 110.5415 - mape: 3034782.7500 - val_loss: 212281.1875 - val_mean_squared_error: 146.6005 - val_mape: 211771.0938\n",
      "Epoch 20/64\n",
      "986/986 [==============================] - 7s 7ms/step - loss: 3481081.7500 - mean_squared_error: 120.1225 - mape: 3479316.5000 - val_loss: 165350.4219 - val_mean_squared_error: 112.7561 - val_mape: 164953.0469\n",
      "Epoch 21/64\n",
      "986/986 [==============================] - 6s 7ms/step - loss: 2321106.0000 - mean_squared_error: 112.1539 - mape: 2319928.7500 - val_loss: 125462.6406 - val_mean_squared_error: 112.4741 - val_mape: 125161.2500\n",
      "Epoch 22/64\n",
      "986/986 [==============================] - 6s 6ms/step - loss: 5074158.0000 - mean_squared_error: 114.9053 - mape: 5071585.0000 - val_loss: 197636.4062 - val_mean_squared_error: 111.0208 - val_mape: 197161.4531\n",
      "Epoch 23/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 334063.9375 - mean_squared_error: 110.0118 - mape: 333894.5312 - val_loss: 203754.1719 - val_mean_squared_error: 107.6344 - val_mape: 203264.6250\n",
      "Epoch 24/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 3250577.2500 - mean_squared_error: 113.9735 - mape: 3248929.0000 - val_loss: 240257.1719 - val_mean_squared_error: 109.7445 - val_mape: 239679.7969\n",
      "Epoch 25/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 2159465.5000 - mean_squared_error: 115.2094 - mape: 2158370.5000 - val_loss: 266699.1250 - val_mean_squared_error: 134.7443 - val_mape: 266058.1875\n",
      "Epoch 26/64\n",
      "986/986 [==============================] - 4s 4ms/step - loss: 2109903.7500 - mean_squared_error: 122.5370 - mape: 2108834.0000 - val_loss: 222751.7500 - val_mean_squared_error: 109.0494 - val_mape: 222216.4531\n",
      "Epoch 27/64\n",
      " 64/986 [>.............................] - ETA: 3s - loss: 63.8062 - mean_squared_error: 93.4556 - mape: 63.8062"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "\n",
    "history = model.fit(\n",
    "        train_features, \n",
    "        train_labels,\n",
    "        validation_split=0.2, \n",
    "        epochs=64,\n",
    "        callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_features, test_labels, batch_size=128)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [length_of_stay]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sns.jointplot(test_labels, predictions, test_labels, kind='hex', gridsize=150, xlim=(0,30), ylim=(0,30))\n",
    "h.set_axis_labels('real length of stay', 'predicted length of stay', fontsize=16)\n",
    "plt.suptitle(f\"{model_name}\")\n",
    "\n",
    "plt.savefig(f\"{model_path}/prediction_{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = predictions - test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(errors, bins=100, range=(-25, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../RoboDocData/95/df95_losh_n32/df95_losh_n32/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"{model_path}/{model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
